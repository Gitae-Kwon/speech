# -*- coding: utf-8 -*-
# í†µì—­ MVP â€” ì…ë ¥(ìŒì„±) â†’ ë²ˆì—­(í…ìŠ¤íŠ¸) â†’ (ì˜µì…˜) ìŒì„±
import io, wave, os
import streamlit as st
from audio_recorder_streamlit import audio_recorder

# ---------------- Page & CSS ----------------
st.set_page_config(page_title="í†µì—­ MVP", page_icon="ğŸ—£ï¸", layout="centered")
st.markdown("""
<style>
div.stButton > button { display:block; margin:0 auto; }
div.stButton > button#swap_btn { width:52px; height:52px; font-size:22px; border-radius:50%; padding:0; }

/* ë§ˆì´í¬ ì•„ì´ì½˜ ê°•ì œ ì¤‘ì•™ ì •ë ¬ */
iframe[title^="audio_recorder_streamlit"] { 
    display:block !important; 
    margin:0 auto !important;
    position: relative !important;
    left: 50% !important;
    transform: translateX(-50%) !important;
}

/* ë§ˆì´í¬ë¥¼ í¬í•¨í•˜ëŠ” ëª¨ë“  ìƒìœ„ div ì¤‘ì•™ ì •ë ¬ */
div[data-testid="column"] > div > div,
div[data-testid="stVerticalBlock"] > div,
.element-container {
    display: flex !important;
    justify-content: center !important;
    align-items: center !important;
    text-align: center !important;
}

/* ë§ˆì´í¬ ì»¨í…Œì´ë„ˆì˜ ì§ì ‘ì ì¸ ë¶€ëª¨ ìš”ì†Œë“¤ */
div:has(iframe[title^="audio_recorder_streamlit"]),
div:has(> div > iframe[title^="audio_recorder_streamlit"]),
div:has(> div > div > iframe[title^="audio_recorder_streamlit"]) {
    display: flex !important;
    justify-content: center !important;
    align-items: center !important;
    width: 100% !important;
    text-align: center !important;
}

/* Streamlit ì»¬ëŸ¼ ë‚´ë¶€ì˜ ì¤‘ì•™ ì •ë ¬ */
[data-testid="column"] {
    display: flex !important;
    justify-content: center !important;
    align-items: center !important;
    flex-direction: column !important;
}

.rec-caption { 
    margin-top:-8px; 
    text-align:center; 
    font-size:0.85rem; 
    color:#666; 
}

/* ì „ì²´ ì»¨í…Œì´ë„ˆ ì¤‘ì•™ ì •ë ¬ ë³´ê°• */
.main .block-container {
    padding-top: 2rem;
    max-width: 600px;
}

/* ì¶”ê°€ì ì¸ ì¤‘ì•™ ì •ë ¬ ë³´ì¥ */
.stApp > div > div > div > div {
    text-align: center;
}
</style>
""", unsafe_allow_html=True)
st.markdown("<h3 style='text-align:center;'>ğŸ—£ï¸ í†µì—­ MVP</h3>", unsafe_allow_html=True)

# ----------- ê°•ì œë¡œ ê¸°ë³¸ ìê²©ì¦ëª… ë¹„í™œì„±(í™˜ê²½ë³€ìˆ˜ ì œê±°) ------------
os.environ.pop("GOOGLE_APPLICATION_CREDENTIALS", None)

# -------------- secrets ê²€ì¦ & ê³µìš© ë¡œë” ----------------
def _load_sa_info():
    try:
        info = dict(st.secrets["gcp_service_account"])
        required = ["type","project_id","private_key","client_email","token_uri"]
        if not all(k in info and info[k] for k in required):
            raise ValueError("secretsì— í•„ìš”í•œ í•„ë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
        return info
    except Exception as e:
        st.error("âŒ .streamlit/secrets.tomlì˜ [gcp_service_account] ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")
        st.code("""ì˜ˆì‹œ:
[gcp_service_account]
type = "service_account"
project_id = "your-project-id"
private_key_id = "..."
private_key = "-----BEGIN PRIVATE KEY-----\\n...\\n-----END PRIVATE KEY-----\\n"
client_email = "svc@your-project-id.iam.gserviceaccount.com"
token_uri = "https://oauth2.googleapis.com/token"
""")
        st.stop()

SA_INFO = _load_sa_info()

@st.cache_resource
def gcp_speech():
    from google.cloud import speech
    return speech.SpeechClient.from_service_account_info(SA_INFO)

@st.cache_resource
def gcp_translate():
    from google.cloud import translate_v2 as translate
    return translate.Client.from_service_account_info(SA_INFO)

@st.cache_resource
def gcp_tts():
    from google.cloud import texttospeech
    return texttospeech.TextToSpeechClient.from_service_account_info(SA_INFO)

# -------------- ë³€í™˜ í—¬í¼ --------------
def _wav_info(wav_bytes: bytes):
    with wave.open(io.BytesIO(wav_bytes), "rb") as w:
        return w.getframerate(), w.getnchannels()

def stt_recognize(wav_bytes: bytes, lang_code: str, alt_codes=None) -> str:
    from google.cloud import speech
    client = gcp_speech()
    sr, ch = _wav_info(wav_bytes)
    cfg = speech.RecognitionConfig(
        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
        sample_rate_hertz=sr,
        language_code=lang_code,
        alternative_language_codes=alt_codes or [],
        enable_automatic_punctuation=True,
        audio_channel_count=ch,
        model="latest_short",  # ì§§ì€ ë°œí™” ìµœì í™”
    )
    audio = speech.RecognitionAudio(content=wav_bytes)
    resp = client.recognize(config=cfg, audio=audio)
    return " ".join(r.alternatives[0].transcript.strip() for r in resp.results).strip()

def translate_text(text: str, target_iso: str) -> str:
    if not text: return ""
    client = gcp_translate()
    return client.translate(text, target_language=target_iso)["translatedText"]

def tts_synthesize(text: str, bcp47_lang: str) -> bytes:
    from google.cloud import texttospeech
    client = gcp_tts()
    s_input = texttospeech.SynthesisInput(text=text)
    voice = texttospeech.VoiceSelectionParams(
        language_code=bcp47_lang, ssml_gender=texttospeech.SsmlVoiceGender.NEUTRAL
    )
    cfg = texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3)
    return client.synthesize_speech(input=s_input, voice=voice, audio_config=cfg).audio_content

# -------------- ì–¸ì–´/ì½”ë“œ í…Œì´ë¸” --------------
LANGS = ["í•œêµ­ì–´","ì˜ì–´","í”„ë‘ìŠ¤ì–´","ì´íƒˆë¦¬ì•„ì–´","ë² íŠ¸ë‚¨ì–´","ì¼ë³¸ì–´","ì¤‘êµ­ì–´(ê°„ì²´)"]
STT_BCP = {"í•œêµ­ì–´":"ko-KR","ì˜ì–´":"en-US","í”„ë‘ìŠ¤ì–´":"fr-FR","ì´íƒˆë¦¬ì•„ì–´":"it-IT","ë² íŠ¸ë‚¨ì–´":"vi-VN","ì¼ë³¸ì–´":"ja-JP","ì¤‘êµ­ì–´(ê°„ì²´)":"zh-CN"}
TRANS_ISO = {"í•œêµ­ì–´":"ko","ì˜ì–´":"en","í”„ë‘ìŠ¤ì–´":"fr","ì´íƒˆë¦¬ì•„ì–´":"it","ë² íŠ¸ë‚¨ì–´":"vi","ì¼ë³¸ì–´":"ja","ì¤‘êµ­ì–´(ê°„ì²´)":"zh"}
TTS_BCP  = {"í•œêµ­ì–´":"ko-KR","ì˜ì–´":"en-US","í”„ë‘ìŠ¤ì–´":"fr-FR","ì´íƒˆë¦¬ì•„ì–´":"it-IT","ë² íŠ¸ë‚¨ì–´":"vi-VN","ì¼ë³¸ì–´":"ja-JP","ì¤‘êµ­ì–´(ê°„ì²´)":"zh-CN"}

# -------------- ìƒíƒœ ê¸°ë³¸ê°’ --------------
if "src_name" not in st.session_state: st.session_state.src_name = "í•œêµ­ì–´"
if "tgt_name" not in st.session_state: st.session_state.tgt_name = "ì˜ì–´"

# -------------- ì–¸ì–´ ì„ íƒ + ìŠ¤ì™‘(ì•„ì´ì½˜ ì¤‘ì•™) --------------
st.selectbox("ì…ë ¥ ì–¸ì–´", LANGS, key="src_name")
def _swap():
    st.session_state.src_name, st.session_state.tgt_name = st.session_state.tgt_name, st.session_state.src_name
st.button("ğŸ”", key="swap_btn", on_click=_swap)
st.selectbox("ëª©í‘œ ì–¸ì–´", LANGS, key="tgt_name")

say_out_loud = st.toggle("ë²ˆì—­ ìŒì„± ì¶œë ¥", value=False)

st.divider()

# -------------- ë§ˆì´í¬(ì •ì¤‘ì•™) + ìº¡ì…˜ ê°„ê²© ì¶•ì†Œ --------------
# ë§ˆì´í¬ ì»¨í…Œì´ë„ˆë¥¼ ì¤‘ì•™ ì •ë ¬ì„ ìœ„í•œ ì»¬ëŸ¼ ì‚¬ìš©
col1, col2, col3 = st.columns([1, 2, 1])
with col2:
    audio_bytes = audio_recorder(text="", recording_color="#ff4b4b",
                                 neutral_color="#2b2b2b", icon_size="2x")

st.markdown("<div class='rec-caption'>ëˆŒëŸ¬ì„œ ë…¹ìŒ / ë‹¤ì‹œ ëˆŒëŸ¬ì„œ ì •ì§€</div>", unsafe_allow_html=True)

# -------------- ì‹¤í–‰ --------------
fallbacks = {
    "ko-KR":["en-US","ja-JP"], "en-US":["ko-KR","fr-FR"], "fr-FR":["en-US","it-IT"],
    "it-IT":["en-US","fr-FR"], "vi-VN":["en-US","ko-KR"], "ja-JP":["en-US","ko-KR"], "zh-CN":["en-US","ko-KR"],
}
src_lang = STT_BCP[st.session_state.src_name]
tgt_iso  = TRANS_ISO[st.session_state.tgt_name]
tgt_tts  = TTS_BCP[st.session_state.tgt_name]
alt_codes = fallbacks.get(src_lang, ["en-US","ko-KR"])

if st.button("ë³€í™˜ ì‹¤í–‰", type="primary", use_container_width=True):
    if not audio_bytes:
        st.warning("ë¨¼ì € ë§ˆì´í¬ë¡œ ë…¹ìŒí•˜ì„¸ìš”.")
    else:
        try:
            src_text = stt_recognize(audio_bytes, src_lang, alt_codes)
            st.text_area("ì›ë¬¸", src_text, height=120)
            tr_text = translate_text(src_text, tgt_iso) if src_text else ""
            st.text_area("ë²ˆì—­", tr_text, height=140)
            if say_out_loud and tr_text:
                try:
                    mp3 = tts_synthesize(tr_text, tgt_tts)
                    st.audio(mp3, format="audio/mp3")
                except Exception as e:
                    st.error("TTS ì¶œë ¥ ì˜¤ë¥˜"); st.exception(e)
        except Exception as e:
            st.error("ë³€í™˜ ì˜¤ë¥˜"); st.exception(e)
