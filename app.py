# -*- coding: utf-8 -*-
# Voice â†’ Translate â†’ (optional) Speech
import io, wave
import streamlit as st

# ---------- GCP Clients ----------
@st.cache_resource
def get_speech_client():
    from google.cloud import speech
    return speech.SpeechClient.from_service_account_info(
        dict(st.secrets["gcp_service_account"])
    )

@st.cache_resource
def get_translate_client():
    from google.cloud import translate_v2 as translate  # v2ê°€ ê°„ë‹¨
    return translate.Client.from_service_account_info(
        dict(st.secrets["gcp_service_account"])
    )

@st.cache_resource
def get_tts_client():
    from google.cloud import texttospeech
    return texttospeech.TextToSpeechClient.from_service_account_info(
        dict(st.secrets["gcp_service_account"])
    )

# ---------- Helpers ----------
def wav_info(wav_bytes: bytes):
    with wave.open(io.BytesIO(wav_bytes), "rb") as w:
        return w.getframerate(), w.getnchannels()

def stt_recognize(wav_bytes: bytes, lang_code: str, alt_codes=None, model="default") -> str:
    from google.cloud import speech
    client = get_speech_client()
    sr, ch = wav_info(wav_bytes)
    config = speech.RecognitionConfig(
        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
        sample_rate_hertz=sr,
        language_code=lang_code,                       # ì˜ˆ: "ko-KR", "vi-VN"
        alternative_language_codes=alt_codes or [],    # ë³´ì¡° ì–¸ì–´
        enable_automatic_punctuation=True,
        audio_channel_count=ch,
        model=model,                                   # "default" | "video" | "phone_call"
    )
    audio = speech.RecognitionAudio(content=wav_bytes)
    resp = client.recognize(config=config, audio=audio)
    return " ".join(r.alternatives[0].transcript.strip() for r in resp.results).strip()

def translate_text(text: str, target_lang: str) -> str:
    # target_lang ì˜ˆ: "ko" "en" "vi" "ja"
    client = get_translate_client()
    return client.translate(text, target_language=target_lang)["translatedText"]

def tts_synthesize(text: str, language_code: str):
    # language_code ì˜ˆ: "vi-VN" "en-US" "ko-KR" â€¦
    from google.cloud import texttospeech
    client = get_tts_client()
    input_text = texttospeech.SynthesisInput(text=text)

    # ë³´ì´ìŠ¤ëŠ” ì–¸ì–´ë§Œ ì§€ì •(ì´ë¦„ ê³ ì • X â†’ ì§€ì—­ ê°€ìš©ì„± ì´ìŠˆ ì¤„ì„)
    voice = texttospeech.VoiceSelectionParams(
        language_code=language_code,
        ssml_gender=texttospeech.SsmlVoiceGender.NEUTRAL,
    )
    audio_config = texttospeech.AudioConfig(
        audio_encoding=texttospeech.AudioEncoding.MP3
    )
    audio = client.synthesize_speech(input=input_text, voice=voice, audio_config=audio_config)
    return audio.audio_content  # bytes (MP3)

# ---------- UI ----------
st.set_page_config(page_title="ìŒì„±â†’ë²ˆì—­â†’(ìŒì„±)", page_icon="ğŸ—£ï¸", layout="centered")
st.title("ğŸ—£ï¸ í†µì—­ MVP â€” ì…ë ¥(ìŒì„±) â†’ ë²ˆì—­(í…ìŠ¤íŠ¸) â†’ ì¶œë ¥(ìŒì„± ON/OFF)")

st.caption("ë§ˆì´í¬ë¡œ ë…¹ìŒ â†’ STT â†’ ë²ˆì—­ â†’ (ì„ íƒ) TTS.  *GCP Speech/Translate/TTS API í™œì„±í™” í•„ìš”*")

# ì–¸ì–´ ì„ íƒ
LANG_INPUT = [
    ("í•œêµ­ì–´", "ko-KR"),
    ("ì˜ì–´(ë¯¸êµ­)", "en-US"),
    ("ì¼ë³¸ì–´", "ja-JP"),
    ("ì¤‘êµ­ì–´(ê°„ì²´)", "zh-CN"),
    ("ìŠ¤í˜ì¸ì–´", "es-ES"),
    ("í”„ë‘ìŠ¤ì–´", "fr-FR"),
    ("ë² íŠ¸ë‚¨ì–´", "vi-VN"),
]
name2code_in = {n:c for n,c in LANG_INPUT}

LANG_TARGET = [
    ("í•œêµ­ì–´", "ko", "ko-KR"),
    ("ì˜ì–´", "en", "en-US"),
    ("ì¼ë³¸ì–´", "ja", "ja-JP"),
    ("ì¤‘êµ­ì–´(ê°„ì²´)", "zh-CN", "zh-CN"),
    ("ìŠ¤í˜ì¸ì–´", "es", "es-ES"),
    ("í”„ë‘ìŠ¤ì–´", "fr", "fr-FR"),
    ("ë² íŠ¸ë‚¨ì–´", "vi", "vi-VN"),
]
tgt_map_iso = {n:iso for n,iso,_ in LANG_TARGET}      # ë²ˆì—­ìš©
tgt_map_tts = {n:bcp for n,_,bcp in LANG_TARGET}      # TTSìš©

c1, c2 = st.columns(2)
with c1:
    src_name = st.selectbox("ì…ë ¥ ìŒì„± ì–¸ì–´", [n for n,_ in LANG_INPUT], index=0)
    src_lang = name2code_in[src_name]
with c2:
    tgt_name = st.selectbox("ë²ˆì—­ ëª©í‘œ ì–¸ì–´", [n for n,_,_ in LANG_TARGET], index=6)  # ê¸°ë³¸: ë² íŠ¸ë‚¨ì–´
    tgt_iso = tgt_map_iso[tgt_name]     # "vi"
    tgt_tts = tgt_map_tts[tgt_name]     # "vi-VN"

c3, c4 = st.columns(2)
with c3:
    autodetect = st.checkbox("ë³´ì¡° ì–¸ì–´ í—ˆìš©(ê°„ì´ ìë™ê°ì§€)", True)
with c4:
    stt_model = st.selectbox("STT ëª¨ë¸", ["default", "video", "phone_call"], index=0)

alt_map = {
    "ko-KR": ["en-US", "ja-JP", "vi-VN"],
    "en-US": ["ko-KR", "ja-JP", "vi-VN"],
    "ja-JP": ["ko-KR", "en-US", "vi-VN"],
    "vi-VN": ["ko-KR", "en-US", "ja-JP"],
}
alt_codes = alt_map.get(src_lang, ["en-US", "ko-KR"]) if autodetect else []

say_out_loud = st.checkbox("ë²ˆì—­ ê²°ê³¼ ìŒì„±ìœ¼ë¡œ ì¶œë ¥(TTS)", value=False)

st.divider()

# ë…¹ìŒ ìœ„ì ¯
from audio_recorder_streamlit import audio_recorder
st.subheader("ğŸ¤ ë§ˆì´í¬ ë…¹ìŒ")
audio_bytes = audio_recorder(
    text="ëˆŒëŸ¬ì„œ ë…¹ìŒ / ë‹¤ì‹œ ëˆŒëŸ¬ì„œ ì •ì§€",
    recording_color="#ff4b4b",
    neutral_color="#2b2b2b",
    icon_size="2x",
)

if audio_bytes:
    st.success("ë…¹ìŒ ì™„ë£Œ! ì•„ë˜ ë²„íŠ¼ìœ¼ë¡œ ë³€í™˜í•˜ì„¸ìš”.")

if st.button("ë³€í™˜ ì‹¤í–‰ (STT â†’ ë²ˆì—­ â†’ TTS)", use_container_width=True, type="primary"):
    if not audio_bytes:
        st.warning("ë¨¼ì € ë§ˆì´í¬ë¡œ ë…¹ìŒí•˜ì„¸ìš”.")
    else:
        try:
            # 1) STT
            src_text = stt_recognize(audio_bytes, src_lang, alt_codes, model=stt_model)
            if not src_text:
                st.warning("ìŒì„±ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            st.text_area("ì›ë¬¸ í…ìŠ¤íŠ¸", src_text, height=140)

            # 2) Translate
            tr_text = translate_text(src_text, tgt_iso) if src_text else ""
            st.text_area(f"ë²ˆì—­ í…ìŠ¤íŠ¸ ({tgt_name})", tr_text, height=140)

            # 3) (ì˜µì…˜) TTS
            if say_out_loud and tr_text:
                try:
                    audio_mp3 = tts_synthesize(tr_text, tgt_tts)
                    st.audio(audio_mp3, format="audio/mp3")
                except Exception as e:
                    st.error("TTS ì¶œë ¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                    st.exception(e)
        except Exception as e:
            st.error("ë³€í™˜ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
            st.exception(e)

st.divider()

# íŒŒì¼ ì—…ë¡œë“œ ëŒ€ì•ˆ
st.subheader("ğŸ“„ WAV íŒŒì¼ ì—…ë¡œë“œ")
up = st.file_uploader("WAV(PCM) íŒŒì¼ ì„ íƒ", type=["wav"])
if up and st.button("ì—…ë¡œë“œ íŒŒì¼ ë³€í™˜", use_container_width=True):
    try:
        src_text = stt_recognize(up.getvalue(), src_lang, alt_codes, model=stt_model)
        st.text_area("ì›ë¬¸ í…ìŠ¤íŠ¸", src_text, height=140, key="up_src")
        tr_text = translate_text(src_text, tgt_iso) if src_text else ""
        st.text_area(f"ë²ˆì—­ í…ìŠ¤íŠ¸ ({tgt_name})", tr_text, height=140, key="up_tr")
        if say_out_loud and tr_text:
            audio_mp3 = tts_synthesize(tr_text, tgt_tts)
            st.audio(audio_mp3, format="audio/mp3")
    except Exception as e:
        st.error("ë³€í™˜ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. (WAV/PCMì¸ì§€ í™•ì¸)")
        st.exception(e)
